<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="shortcut icon" href="../img/favicon.ico">
    <title>Lessons Learned &mdash; ML-Lab</title>
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/tonsky/FiraCode@1.206/distr/fira_code.css">
    <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.8.1/css/all.css">
    <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.8.1/css/v4-shims.css">
    <link rel="stylesheet" href="../css/theme.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
    <script src="//code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script>
        hljs.initHighlightingOnLoad();
    </script> 
</head>

<body ontouchstart="">
    <div id="container">
        <aside>
            <div class="home">
                <div class="title">
                    <button class="hamburger"></button>
                    <a href=".." class="site-name"> ML-Lab</a>
                </div>
                <div class="search">
                    <div role="search">
    <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
        <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
    </form>
</div>
                </div>
            </div>
            <nav class="nav">
                <ul class="root">
                    <li class="toctree-l1"><a class="nav-item" href="..">Home</a></li>
                    <li class="toctree-l1 current"><a class="nav-item current" href="./">Lessons Learned</a>
<ul class="subnav">
<li class="toctree-l2"><a class="nav-item toc" href="#0-mini-glossario-3-parole-che-tornano-sempre">0) Mini-glossario (3 parole che tornano sempre)</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#1-cosa-stiamo-facendo">1) Cosa stiamo facendo</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#2-fit-buono-vs-fit-cattivo">2) Fit buono vs fit cattivo</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#3-decision-tree-albero">3) Decision Tree (albero)</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#4-come-scegliere-gli-iperparametri-senza-barare">4) Come scegliere gli iperparametri senza barare</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#5-classi-sbilanciate-laccuracy-mente">5) Classi sbilanciate: l’accuracy mente</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#6-f1-e-roc-auc-in-due-righe">6) F1 e ROC-AUC in due righe</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#7-la-soglia-05-non-e-legge">7) La soglia: 0.5 non è legge</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#8-scaling-quando-si-e-quando-no">8) Scaling: quando sì e quando no</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#9-random-forest-perche-funziona-e-dove-punge">9) Random Forest: perché funziona e dove punge</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#10-importanza-delle-feature-evitare-abbagli">10) “Importanza” delle feature: evitare abbagli</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#11-leakage-barare-senza-volerlo">11) Leakage: barare senza volerlo</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#12-workflow-che-non-ti-tradisce">12) Workflow che non ti tradisce</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#13-regole-veloci-da-campo">13) Regole veloci da campo</a></li>
<li class="toctree-l2"><a class="nav-item toc" href="#14-debug-veloce-checklist">14) Debug veloce (checklist)</a></li>
</ul></li>
                    <li class="toctree-l1"><a class="nav-item" href="../script/">Script</a></li>
                    <li class="toctree-l1"><a class="nav-item" href="../quiz/">Quiz</a></li>
                </ul>
            </nav>
            <div class="repo">
    <div class="link">
    </div>
    <div class="previous"><a href="..">&laquo; Previous</a></div>
    <div class="next"><a href="../script/">Next &raquo;</a></div>
</div>
        </aside>
        <div id="spacer"><button class="arrow"></button></div>
        <main>
            <div class="home-top">
                <button class="hamburger"></button>
                <a href=".." class="site-name"> ML-Lab</a>
            </div>
            <div id="main">
                <nav class="breadcrumbs">
<ul>
    
</ul>
</nav>
                <div id="content"><h1 id="ml-lessons-learned-versione-terra-terra-aggiornata">ML — Lessons Learned (versione “terra-terra”, aggiornata)<a class="headerlink" href="#ml-lessons-learned-versione-terra-terra-aggiornata" title="Permanent link">&para;</a></h1>
<p>Di seguito il riassunto che useremmo davvero in lab: spiegato semplice, con esempi concreti e zero fuffa.</p>
<hr />
<h2 id="0-mini-glossario-3-parole-che-tornano-sempre">0) Mini-glossario (3 parole che tornano sempre)<a class="headerlink" href="#0-mini-glossario-3-parole-che-tornano-sempre" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Parametri</strong>: numeri che il modello <em>impara</em> (es. pesi della logistica).</li>
<li><strong>Iperparametri</strong>: manopole che <em>scegli tu</em> (es. <code>max_depth</code> di un albero, <code>C</code> della logistica).</li>
<li><strong>Fit</strong>: l’atto di far apprendere il modello dal <strong>train</strong>.</li>
</ul>
<hr />
<h2 id="1-cosa-stiamo-facendo">1) Cosa stiamo facendo<a class="headerlink" href="#1-cosa-stiamo-facendo" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>ML = imparare una funzione <code>input → output</code> dai dati.</strong>
  Non scrivi la formula a mano: la stima il modello minimizzando un errore.</li>
<li><strong>Metodo onesto:</strong> separa sempre i dati in <strong>train</strong> (si impara) e <strong>test</strong> (si misura).
  <strong>Il test è sacro</strong>: non lo usi per scegliere nulla.</li>
</ul>
<hr />
<h2 id="2-fit-buono-vs-fit-cattivo">2) Fit buono vs fit cattivo<a class="headerlink" href="#2-fit-buono-vs-fit-cattivo" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Overfitting:</strong> vola su <strong>train</strong>, crolla su <strong>test</strong> → ha imparato anche il rumore.
  <em>Sintomi:</em> modello troppo complesso, regole iper-specifiche.</li>
<li><strong>Underfitting:</strong> scarso sia su train sia su test → modello troppo semplice o features povere.</li>
<li><strong>Che fare:</strong> confronta <strong>train vs test</strong>, regola la complessità (es. <code>max_depth</code>, <code>C</code>), aggiungi features/dati migliori.</li>
</ul>
<hr />
<h2 id="3-decision-tree-albero">3) Decision Tree (albero)<a class="headerlink" href="#3-decision-tree-albero" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Pro:</strong> regole leggibili (<em>SE … ALLORA …</em>), spiegazioni facili.</li>
<li><strong>Manopole principali:</strong> <code>max_depth</code>, <code>min_samples_leaf</code>, <code>max_leaf_nodes</code>.</li>
<li><strong>Nota:</strong> un singolo albero è <strong>instabile</strong> (alta varianza). La <strong>Random Forest</strong> media molti alberi e stabilizza.</li>
</ul>
<hr />
<h2 id="4-come-scegliere-gli-iperparametri-senza-barare">4) Come scegliere gli iperparametri senza barare<a class="headerlink" href="#4-come-scegliere-gli-iperparametri-senza-barare" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>k-fold cross-validation</strong> sul <strong>solo train</strong> (es. 5-fold).
  Media e deviazione ti dicono qualità e incertezza.</li>
<li><strong>Regola “1-SE”:</strong> se più settaggi sono quasi pari, scegli <strong>il più semplice</strong>.</li>
<li><strong>Dataset piccolo?</strong> Fai <strong>CV ripetuta</strong> (es. 5×5-fold) per avere una media più stabile.</li>
</ul>
<hr />
<h2 id="5-classi-sbilanciate-laccuracy-mente">5) Classi sbilanciate: l’accuracy mente<a class="headerlink" href="#5-classi-sbilanciate-laccuracy-mente" title="Permanent link">&para;</a></h2>
<ul>
<li>Se il 90% è classe 0, dire sempre “0” dà <strong>accuracy 0.90</strong>… ma non serve a nulla.</li>
<li>Guarda <strong>Precision</strong> (pochi falsi allarmi), <strong>Recall</strong> (pochi positivi persi), <strong>F1</strong> (equilibrio tra i due).</li>
<li><strong>Confusion matrix</strong> = tavolo della verità: TN, FP, FN, TP.</li>
</ul>
<p><strong>Esempio lampo (100 casi):</strong>
Predici 40 positivi → 30 giusti (TP) e 10 falsi allarmi (FP).
Ci sono 35 positivi reali: ne hai persi 5 (FN).</p>
<ul>
<li>Precision = 30/(30+10)=0.75</li>
<li>Recall = 30/(30+5)=0.86</li>
<li>F1 ≈ 0.80</li>
</ul>
<hr />
<h2 id="6-f1-e-roc-auc-in-due-righe">6) F1 e ROC-AUC in due righe<a class="headerlink" href="#6-f1-e-roc-auc-in-due-righe" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>F1:</strong> numero unico che sale solo se <strong>precision</strong> e <strong>recall</strong> sono <strong>entrambi</strong> alti.
  <code>F1 = 2 · (Prec·Rec) / (Prec + Rec)</code></li>
<li><strong>ROC-AUC:</strong> qualità del <strong>ranking</strong> delle probabilità su <strong>tutte</strong> le soglie.
  0.5 = a caso, 1.0 = perfetto. <em>Non dipende</em> dalla soglia 0.5.</li>
</ul>
<blockquote>
<p>Nota: con sbilanciamenti <strong>molto</strong> forti, guarda anche la <strong>PR-AUC</strong> (area Precision-Recall).</p>
</blockquote>
<hr />
<h2 id="7-la-soglia-05-non-e-legge">7) La soglia: 0.5 non è legge<a class="headerlink" href="#7-la-soglia-05-non-e-legge" title="Permanent link">&para;</a></h2>
<p>Cambiare soglia scambia <strong>FP ↔ FN</strong>. Tre modi pratici per sceglierla:</p>
<ol>
<li><strong>Auto-threshold su validation</strong> (dal <strong>train</strong>): massimizza F1 (o Youden <code>TPR−FPR</code>).</li>
<li><strong>A costo:</strong> scegli <code>soglia</code> che minimizza <code>c_fp·FP + c_fn·FN</code> (decidi tu quanto pesa un FN vs FP).</li>
<li><strong>Sweep tabellare:</strong> stampa soglia → (FP, FN, Precision, Recall, F1) e guardala.</li>
</ol>
<p><strong>Regola pratica:</strong></p>
<ul>
<li>Se <strong>perdere un positivo fa male</strong> → soglia <strong>più bassa</strong> (recall su, più FP).</li>
<li>Se <strong>odi i falsi allarmi</strong> → soglia <strong>più alta</strong> (precision su, più FN).</li>
</ul>
<hr />
<h2 id="8-scaling-quando-si-e-quando-no">8) Scaling: quando sì e quando no<a class="headerlink" href="#8-scaling-quando-si-e-quando-no" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Serve</strong> a modelli basati su distanze/geometria: <strong>Logistica</strong>, <strong>SVM</strong>, <strong>k-NN</strong>, <strong>PCA</strong>.</li>
<li><strong>Non serve in genere</strong> per <strong>Alberi/Random Forest</strong> (si basano su soglie, non su distanze).</li>
</ul>
<hr />
<h2 id="9-random-forest-perche-funziona-e-dove-punge">9) Random Forest: perché funziona e dove punge<a class="headerlink" href="#9-random-forest-perche-funziona-e-dove-punge" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Pro:</strong> cattura <strong>non-linearità</strong> e <strong>interazioni</strong>, robusta al rumore, buona “out-of-the-box”.</li>
<li><strong>Contro tipico:</strong> le <strong>probabilità</strong> possono essere <strong>poco calibrate</strong> → 0.5 spesso non è la soglia giusta.</li>
<li>
<p><strong>Rimedi:</strong></p>
</li>
<li>
<p>scegli bene la <strong>soglia</strong> (auto/costo/sweep),</p>
</li>
<li>valuta <code>class_weight='balanced'</code> se la positiva è rara,</li>
<li><strong>calibra</strong> le probabilità (<strong>sigmoid/Platt</strong> o <strong>isotonic</strong>) se ti servono score affidabili.</li>
</ul>
<hr />
<h2 id="10-importanza-delle-feature-evitare-abbagli">10) “Importanza” delle feature: evitare abbagli<a class="headerlink" href="#10-importanza-delle-feature-evitare-abbagli" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Impurity importance</strong> (<code>feature_importances_</code>): rapida, ma <strong>favorisce</strong> variabili con molte soglie e soffre con <strong>feature molto correlate</strong> (le “sorelle” si dividono il merito).</li>
<li><strong>Permutation importance</strong> (su <strong>TEST</strong> e con una metrica, es. ROC-AUC): misuri <em>quanto peggiora</em> il modello quando rompi una feature → spesso più onesta.</li>
<li><strong>Ablation test:</strong> rimuovi la top-1/top-k e rimisura. Se l’AUC non scende, c’è <strong>ridondanza</strong> (più feature dicono la stessa cosa).</li>
</ul>
<hr />
<h2 id="11-leakage-barare-senza-volerlo">11) Leakage: barare senza volerlo<a class="headerlink" href="#11-leakage-barare-senza-volerlo" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Cos’è:</strong> usare info del <strong>test</strong> (o del fold di validazione) per calcolare imputazioni, scaling, encoding, selezione feature…
  Risultato: metriche gonfiate.</li>
<li><strong>Regola d’oro:</strong> tutte le trasformazioni si <strong>fittano solo sul train</strong>.</li>
<li><strong>Strumenti che ti proteggono:</strong> <strong>Pipeline</strong> (e <strong>ColumnTransformer</strong> per numeriche+categoriche) + <strong>GridSearchCV</strong> <em>sulla pipeline</em>.</li>
<li><strong>Spia rossa:</strong> CV troppo bella dopo aver preprocessato <em>prima</em> della CV.</li>
</ul>
<hr />
<h2 id="12-workflow-che-non-ti-tradisce">12) Workflow che non ti tradisce<a class="headerlink" href="#12-workflow-che-non-ti-tradisce" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Split</strong> train/test (il test in cassaforte).</li>
<li>Sul <strong>train</strong>: costruisci <strong>Pipeline</strong> (preprocess + modello).</li>
<li><strong>CV</strong> (anche ripetuta) per <strong>tuning</strong> iperparametri (regola 1-SE se pari).</li>
<li><strong>Soglia</strong>: scegli su validation/OOF o per <strong>costo</strong>.</li>
<li><strong>Fit finale</strong> sul train completo con pipeline + iperparametri + soglia scelti.</li>
<li><strong>Test una sola volta</strong>: F1, ROC-AUC, confusion; se serve, <strong>calibrazione</strong> (Brier, reliability bins).</li>
<li><strong>Spiega</strong>: importanze (impurity + permutation) e, se serve, ablation.</li>
</ol>
<hr />
<h2 id="13-regole-veloci-da-campo">13) Regole veloci da campo<a class="headerlink" href="#13-regole-veloci-da-campo" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Mai</strong> usare il test per scegliere iperparametri o soglia.</li>
<li>Dataset piccolo → <strong>CV ripetuta</strong> + regola <strong>1-SE</strong>.</li>
<li><strong>Sbilanciamento:</strong> valuta <strong>F1</strong> e/o <strong>Recall</strong> (se i FN costano), usa <strong>ROC-AUC</strong> per confrontare modelli e <strong>PR-AUC</strong> se lo sbilanciamento è estremo.</li>
<li><strong>RF:</strong> non fissarti su 0.5; <strong>scegli soglia</strong> e valuta <strong>calibrazione</strong>.</li>
<li><strong>Logistica:</strong> con scaling, spesso imbattibile su confini quasi lineari; <strong>probabilità molto affidabili</strong>.</li>
</ul>
<hr />
<h2 id="14-debug-veloce-checklist">14) Debug veloce (checklist)<a class="headerlink" href="#14-debug-veloce-checklist" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Baseline</strong>: quanto fa un dummy che predice la classe più frequente?</li>
<li><strong>Leakage</strong>: sto facendo imputazione/scaling <em>fuori</em> pipeline?</li>
<li><strong>Metriche giuste</strong>: sto guardando F1/Recall oltre all’accuracy?</li>
<li><strong>Soglia</strong>: ho provato auto-threshold o a costo?</li>
<li><strong>Varianza</strong>: risultati stabili cambiando <strong>seed</strong>? (se no, CV ripetuta)</li>
<li><strong>Ridondanza</strong>: feature molto correlate? Usa permutation + ablation.</li>
</ol>
<hr /></div>
                <footer>
    <div class="footer-buttons">
        <div class="previous"><a href=".." title="Home"><span>Previous</span></a></div>
        <div class="next"><a href="../script/" title="Script"><span>Next</span></a></div>
    </div>
    <div class="footer-note">
        <p>
            Built with <a href="http://www.mkdocs.org">MkDocs</a> using
            <a href="https://github.com/daizutabi/mkdocs-ivory">Ivory theme</a>.
        </p>
    </div>
</footer>
            </div>
        </main>
    </div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
    <script src="../search/main.js"></script>
</body>

</html>